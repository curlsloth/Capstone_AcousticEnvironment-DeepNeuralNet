{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Lf9wooRbilYQ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-14 23:34:50.399940: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random as python_random\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras import regularizers\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "2Fne5qV1iR5v"
   },
   "outputs": [],
   "source": [
    "aggregated_data = pickle.load( open( '../data/processed/20230304/aggregated_data', 'rb' ) )\n",
    "\n",
    "[train_mps_raw_pca, valid_mps_raw_pca, test_mps_raw_pca,\n",
    "    train_mps_bg_pca, valid_mps_bg_pca, test_mps_bg_pca,\n",
    "    train_mps_fg_pca, valid_mps_fg_pca, test_mps_fg_pca,\n",
    "    train_indices_raw_pca, valid_indices_raw_pca, test_indices_raw_pca,\n",
    "    train_indices_bg_pca, valid_indices_bg_pca, test_indices_bg_pca,\n",
    "    train_indices_fg_pca, valid_indices_fg_pca, test_indices_fg_pca,\n",
    "    train_embedding_raw_pca, valid_embedding_raw_pca, test_embedding_raw_pca,\n",
    "    train_embedding_bg_pca, valid_embedding_bg_pca, test_embedding_bg_pca,\n",
    "    train_embedding_fg_pca, valid_embedding_fg_pca, test_embedding_fg_pca,\n",
    "    train_vgg_raw_pca, valid_vgg_raw_pca, test_vgg_raw_pca,\n",
    "    train_vgg_bg_pca, valid_vgg_bg_pca, test_vgg_bg_pca,\n",
    "    train_vgg_fg_pca, valid_vgg_fg_pca, test_vgg_fg_pca,\n",
    "    train_panns_clip_raw_pca, valid_panns_clip_raw_pca, test_panns_clip_raw_pca,\n",
    "    train_panns_clip_bg_pca, valid_panns_clip_bg_pca, test_panns_clip_bg_pca,\n",
    "    train_panns_clip_fg_pca, valid_panns_clip_fg_pca, test_panns_clip_fg_pca,\n",
    "    train_panns_embedding_raw_pca, valid_panns_embedding_raw_pca, test_panns_embedding_raw_pca,\n",
    "    train_panns_embedding_bg_pca, valid_panns_embedding_bg_pca, test_panns_embedding_bg_pca,\n",
    "    train_panns_embedding_fg_pca, valid_panns_embedding_fg_pca, test_panns_embedding_fg_pca,\n",
    "    y_train, y_valid, y_test] = aggregated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "hYt1UQ3kiyYQ"
   },
   "outputs": [],
   "source": [
    "# # YAMNet\n",
    "# train_data_raw = np.concatenate((train_mps_raw_pca, train_indices_raw_pca, train_embedding_raw_pca, train_vgg_raw_pca), axis = 1)\n",
    "# valid_data_raw = np.concatenate((valid_mps_raw_pca, valid_indices_raw_pca, valid_embedding_raw_pca, valid_vgg_raw_pca), axis = 1)\n",
    "# test_data_raw = np.concatenate((test_mps_raw_pca, test_indices_raw_pca, test_embedding_raw_pca, test_vgg_raw_pca), axis = 1)\n",
    "\n",
    "# train_data_bg = np.concatenate((train_mps_bg_pca, train_indices_bg_pca, train_embedding_bg_pca, train_vgg_bg_pca), axis = 1)\n",
    "# valid_data_bg = np.concatenate((valid_mps_bg_pca, valid_indices_bg_pca, valid_embedding_bg_pca, valid_vgg_bg_pca), axis = 1)\n",
    "# test_data_bg = np.concatenate((test_mps_bg_pca, test_indices_bg_pca, test_embedding_bg_pca, test_vgg_bg_pca), axis = 1)\n",
    "\n",
    "# train_data_fg = np.concatenate((train_mps_fg_pca, train_indices_fg_pca, train_embedding_fg_pca, train_vgg_fg_pca), axis = 1)\n",
    "# valid_data_fg = np.concatenate((valid_mps_fg_pca, valid_indices_fg_pca, valid_embedding_fg_pca, valid_vgg_fg_pca), axis = 1)\n",
    "# test_data_fg = np.concatenate((test_mps_fg_pca, test_indices_fg_pca, test_embedding_fg_pca, test_vgg_fg_pca), axis = 1)\n",
    "\n",
    "# train_data_all = np.concatenate((train_data_raw, train_data_bg, train_data_fg), axis = 1)\n",
    "# valid_data_all = np.concatenate((valid_data_raw, valid_data_bg, valid_data_fg), axis = 1)\n",
    "# test_data_all = np.concatenate((test_data_raw, test_data_bg, test_data_fg), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGG\n",
    "train_data_raw = np.concatenate((train_mps_raw_pca, train_indices_raw_pca, train_vgg_raw_pca), axis = 1)\n",
    "valid_data_raw = np.concatenate((valid_mps_raw_pca, valid_indices_raw_pca, valid_vgg_raw_pca), axis = 1)\n",
    "test_data_raw = np.concatenate((test_mps_raw_pca, test_indices_raw_pca, test_vgg_raw_pca), axis = 1)\n",
    "\n",
    "train_data_bg = np.concatenate((train_mps_bg_pca, train_indices_bg_pca, train_vgg_bg_pca), axis = 1)\n",
    "valid_data_bg = np.concatenate((valid_mps_bg_pca, valid_indices_bg_pca, valid_vgg_bg_pca), axis = 1)\n",
    "test_data_bg = np.concatenate((test_mps_bg_pca, test_indices_bg_pca, test_vgg_bg_pca), axis = 1)\n",
    "\n",
    "train_data_fg = np.concatenate((train_mps_fg_pca, train_indices_fg_pca, train_vgg_fg_pca), axis = 1)\n",
    "valid_data_fg = np.concatenate((valid_mps_fg_pca, valid_indices_fg_pca, valid_vgg_fg_pca), axis = 1)\n",
    "test_data_fg = np.concatenate((test_mps_fg_pca, test_indices_fg_pca, test_vgg_fg_pca), axis = 1)\n",
    "\n",
    "train_data_all = np.concatenate((train_data_raw, train_data_bg, train_data_fg), axis = 1)\n",
    "valid_data_all = np.concatenate((valid_data_raw, valid_data_bg, valid_data_fg), axis = 1)\n",
    "test_data_all = np.concatenate((test_data_raw, test_data_bg, test_data_fg), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # including panns embeddings\n",
    "# train_data_raw = np.concatenate((train_mps_raw_pca, train_indices_raw_pca, train_panns_embedding_raw_pca), axis = 1)\n",
    "# valid_data_raw = np.concatenate((valid_mps_raw_pca, valid_indices_raw_pca, valid_panns_embedding_raw_pca), axis = 1)\n",
    "# test_data_raw = np.concatenate((test_mps_raw_pca, test_indices_raw_pca, test_panns_embedding_raw_pca), axis = 1)\n",
    "\n",
    "# train_data_bg = np.concatenate((train_mps_bg_pca, train_indices_bg_pca, train_panns_embedding_bg_pca), axis = 1)\n",
    "# valid_data_bg = np.concatenate((valid_mps_bg_pca, valid_indices_bg_pca, valid_panns_embedding_bg_pca), axis = 1)\n",
    "# test_data_bg = np.concatenate((test_mps_bg_pca, test_indices_bg_pca, test_panns_embedding_bg_pca), axis = 1)\n",
    "\n",
    "# train_data_fg = np.concatenate((train_mps_fg_pca, train_indices_fg_pca, train_panns_embedding_fg_pca), axis = 1)\n",
    "# valid_data_fg = np.concatenate((valid_mps_fg_pca, valid_indices_fg_pca, valid_panns_embedding_fg_pca), axis = 1)\n",
    "# test_data_fg = np.concatenate((test_mps_fg_pca, test_indices_fg_pca, test_panns_embedding_fg_pca), axis = 1)\n",
    "\n",
    "# train_data_all = np.concatenate((train_data_raw, train_data_bg, train_data_fg), axis = 1)\n",
    "# valid_data_all = np.concatenate((valid_data_raw, valid_data_bg, valid_data_fg), axis = 1)\n",
    "# test_data_all = np.concatenate((test_data_raw, test_data_bg, test_data_fg), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11933, 558)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_fg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11933, 1674)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_all.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lazy predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from lazypredict.Supervised import LazyClassifier\n",
    "# clf = LazyClassifier(verbose=0, ignore_warnings=True, custom_metric=None)\n",
    "# models,predictions = clf.fit(train_vgg_bg_pca, valid_vgg_bg_pca, y_train, y_valid)\n",
    "# models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XdHjNS8fnvej"
   },
   "source": [
    "# Tensorflow parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "NAbJ5gLwnutk"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import keras_tuner as kt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "TNtZTp_wn6Zc"
   },
   "outputs": [],
   "source": [
    "def build_model_narrow(hp):\n",
    "\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Input(shape=(train_data_raw.shape[1]), dtype=tf.float32))\n",
    "    drop_rate = hp.Float(\"dr\", min_value=0.2, max_value=0.5, sampling=\"linear\")\n",
    "#         if hp.Boolean(\"dropout\"):\n",
    "    model.add(layers.Dropout(rate=drop_rate))\n",
    "    # Tune the number of layers.\n",
    "    for i in range(hp.Int(\"num_layers\", 1, 10)):\n",
    "        model.add(\n",
    "            layers.Dense(\n",
    "                # Tune number of units separately.\n",
    "                units=hp.Int(f\"units_{i}\", min_value=10, max_value=200, step=10),\n",
    "                activation=hp.Choice(\"activation\", [\"relu\", \"tanh\"]),\n",
    "            )\n",
    "        )\n",
    "        model.add(layers.Dropout(rate=drop_rate))\n",
    "    model.add(layers.Dense(2))\n",
    "    learning_rate = hp.Float(\"lr\", min_value=1e-4, max_value=1e-2, sampling=\"log\")\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "def build_model_wide(hp):\n",
    "\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Input(shape=(train_data_all.shape[1]), dtype=tf.float32))\n",
    "    drop_rate = hp.Float(\"dr\", min_value=0.2, max_value=0.5, sampling=\"linear\")\n",
    "#         if hp.Boolean(\"dropout\"):\n",
    "    model.add(layers.Dropout(rate=drop_rate))\n",
    "    # Tune the number of layers.\n",
    "    for i in range(hp.Int(\"num_layers\", 1, 10)):\n",
    "        model.add(\n",
    "            layers.Dense(\n",
    "                # Tune number of units separately.\n",
    "                units=hp.Int(f\"units_{i}\", min_value=10, max_value=500, step=50),\n",
    "                activation=hp.Choice(\"activation\", [\"relu\", \"tanh\"]),\n",
    "            )\n",
    "        )\n",
    "        model.add(layers.Dropout(rate=drop_rate))\n",
    "    model.add(layers.Dense(2))\n",
    "    learning_rate = hp.Float(\"lr\", min_value=1e-4, max_value=1e-2, sampling=\"log\")\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_AUC_narrow(hp):\n",
    "\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Input(shape=(train_data_raw.shape[1]), dtype=tf.float32))\n",
    "    drop_rate = hp.Float(\"dr\", min_value=0.0, max_value=0.5, sampling=\"linear\")\n",
    "#         if hp.Boolean(\"dropout\"):\n",
    "    model.add(layers.Dropout(rate=drop_rate))\n",
    "    # Tune the number of layers.\n",
    "    for i in range(hp.Int(\"num_layers\", 1, 5)):\n",
    "        model.add(\n",
    "            layers.Dense(\n",
    "                # Tune number of units separately.\n",
    "                units=hp.Int(f\"units_{i}\", min_value=16, max_value=256, step=16),\n",
    "                activation=hp.Choice(\"activation\", [\"relu\", \"tanh\"]),\n",
    "            )\n",
    "        )\n",
    "        model.add(layers.Dropout(rate=drop_rate))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    learning_rate = hp.Float(\"lr\", min_value=1e-4, max_value=1e-2, sampling=\"log\")\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "#         loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        metrics=[tf.keras.metrics.AUC(name='AUC')],\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "def build_model_AUC_wide(hp):\n",
    "\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Input(shape=(train_data_all.shape[1]), dtype=tf.float32))\n",
    "    drop_rate = hp.Float(\"dr\", min_value=0.0, max_value=0.5, sampling=\"linear\")\n",
    "#         if hp.Boolean(\"dropout\"):\n",
    "    model.add(layers.Dropout(rate=drop_rate))\n",
    "    # Tune the number of layers.\n",
    "    for i in range(hp.Int(\"num_layers\", 1, 5)):\n",
    "        model.add(\n",
    "            layers.Dense(\n",
    "                # Tune number of units separately.\n",
    "                units=hp.Int(f\"units_{i}\", min_value=16, max_value=512, step=16),\n",
    "                activation=hp.Choice(\"activation\", [\"relu\", \"tanh\"]),\n",
    "            )\n",
    "        )\n",
    "        model.add(layers.Dropout(rate=drop_rate))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    learning_rate = hp.Float(\"lr\", min_value=1e-4, max_value=1e-2, sampling=\"log\")\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "        metrics=[tf.keras.metrics.AUC(name='AUC')],\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "x_Gu5t5w5BkJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Tuner from ../model/BinaryCrossentropy_valAUC/kt_Bayesian_raw_0314_YAMNetEmbedding/tuner0.json\n",
      "INFO:tensorflow:Reloading Tuner from ../model/BinaryCrossentropy_valAUC/kt_Bayesian_bg_0314_YAMNetEmbedding/tuner0.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-14 23:34:56.158714: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Tuner from ../model/BinaryCrossentropy_valAUC/kt_Bayesian_fg_0314_YAMNetEmbedding/tuner0.json\n",
      "INFO:tensorflow:Reloading Tuner from ../model/BinaryCrossentropy_valAUC/kt_Bayesian_all_0314_YAMNetEmbedding/tuner0.json\n"
     ]
    }
   ],
   "source": [
    "directory = '../model/BinaryCrossentropy_valAUC'\n",
    "feat_name = '0314_vggEmbedding'\n",
    "\n",
    "tuner_raw = kt.BayesianOptimization(build_model_AUC_narrow,\n",
    "                     objective='val_AUC',\n",
    "                     max_trials=100,\n",
    "                     num_initial_points=25,\n",
    "                     seed=23,\n",
    "#                      overwrite=True,\n",
    "                     directory=directory,\n",
    "#                      distribution_strategy=tf.distribute.MirroredStrategy(),\n",
    "                     project_name='kt_Bayesian_raw_'+feat_name)\n",
    "\n",
    "tuner_bg = kt.BayesianOptimization(build_model_AUC_narrow,\n",
    "                     objective='val_AUC',\n",
    "                     max_trials=100,\n",
    "                     num_initial_points=25,\n",
    "                     seed=23,\n",
    "#                      overwrite=True,\n",
    "                     directory=directory,\n",
    "#                      distribution_strategy=tf.distribute.MirroredStrategy(),\n",
    "                     project_name='kt_Bayesian_bg_'+feat_name)\n",
    "\n",
    "tuner_fg = kt.BayesianOptimization(build_model_AUC_narrow,\n",
    "                     objective='val_AUC',\n",
    "                     max_trials=100,\n",
    "                     num_initial_points=25,\n",
    "                     seed=23,\n",
    "#                      overwrite=True,\n",
    "                     directory=directory,\n",
    "#                      distribution_strategy=tf.distribute.MirroredStrategy(),\n",
    "                     project_name='kt_Bayesian_fg_'+feat_name)\n",
    "\n",
    "tuner_all = kt.BayesianOptimization(build_model_AUC_wide,\n",
    "                     objective='val_AUC',\n",
    "                     max_trials=100,\n",
    "                     num_initial_points=25,\n",
    "                     seed=23,\n",
    "#                      overwrite=True,\n",
    "                     directory=directory,\n",
    "#                      distribution_strategy=tf.distribute.MirroredStrategy(),\n",
    "                     project_name='kt_Bayesian_all_'+feat_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "1mjOQ8bdqpZp"
   },
   "outputs": [],
   "source": [
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner_all.search(train_data_all, y_train, epochs=50, validation_data=(valid_data_all, y_valid), callbacks=[stop_early], use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "WB0ar_NJNvTo",
    "outputId": "8031003a-9996-4735-e672-507666562056",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner_bg.search(train_data_bg, y_train, epochs=50, validation_data=(valid_data_bg, y_valid), callbacks=[stop_early], use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7JMqwp6fqvUi",
    "outputId": "3c1079c0-1f3f-4917-8363-cb1b269c26ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner_raw.search(train_data_raw, y_train, epochs=50, validation_data=(valid_data_raw, y_valid), callbacks=[stop_early], use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "hY6yptDENxeQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner_fg.search(train_data_fg, y_train, epochs=50, validation_data=(valid_data_fg, y_valid), callbacks=[stop_early], use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in ../model/BinaryCrossentropy_valAUC/kt_Bayesian_raw_0314_YAMNetEmbedding\n",
      "Showing 1 best trials\n",
      "<keras_tuner.engine.objective.Objective object at 0x7fd8bbde52e0>\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "dr: 0.5\n",
      "num_layers: 1\n",
      "units_0: 208\n",
      "activation: tanh\n",
      "lr: 0.0001\n",
      "units_1: 32\n",
      "units_2: 256\n",
      "units_3: 256\n",
      "units_4: 256\n",
      "Score: 0.792046070098877\n"
     ]
    }
   ],
   "source": [
    "tuner_raw.results_summary(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in ../model/BinaryCrossentropy_valAUC/kt_Bayesian_bg_0314_YAMNetEmbedding\n",
      "Showing 1 best trials\n",
      "<keras_tuner.engine.objective.Objective object at 0x7fd8bbedf700>\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "dr: 0.3708344678072866\n",
      "num_layers: 4\n",
      "units_0: 240\n",
      "activation: relu\n",
      "lr: 0.00014023399602325874\n",
      "units_1: 80\n",
      "units_2: 224\n",
      "units_3: 128\n",
      "Score: 0.7902377843856812\n"
     ]
    }
   ],
   "source": [
    "tuner_bg.results_summary(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in ../model/BinaryCrossentropy_valAUC/kt_Bayesian_fg_0314_YAMNetEmbedding\n",
      "Showing 1 best trials\n",
      "<keras_tuner.engine.objective.Objective object at 0x7fd8cd75a6a0>\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "dr: 0.48339085979399293\n",
      "num_layers: 1\n",
      "units_0: 16\n",
      "activation: relu\n",
      "lr: 0.0002609603134449437\n",
      "units_1: 128\n",
      "units_2: 208\n",
      "units_3: 128\n",
      "units_4: 176\n",
      "Score: 0.7421988844871521\n"
     ]
    }
   ],
   "source": [
    "tuner_fg.results_summary(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in ../model/BinaryCrossentropy_valAUC/kt_Bayesian_all_0314_YAMNetEmbedding\n",
      "Showing 1 best trials\n",
      "<keras_tuner.engine.objective.Objective object at 0x7fd8ab292610>\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "dr: 0.5\n",
      "num_layers: 1\n",
      "units_0: 16\n",
      "activation: tanh\n",
      "lr: 0.0001\n",
      "units_1: 512\n",
      "units_2: 512\n",
      "units_3: 448\n",
      "units_4: 512\n",
      "Score: 0.792080283164978\n"
     ]
    }
   ],
   "source": [
    "tuner_all.results_summary(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras_tuner.engine.hyperparameters.hyperparameters.HyperParameters at 0x7fd8882b9ca0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuner_all.get_best_hyperparameters(num_trials=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
