{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e77891e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-10 14:44:52.317297: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-10 14:44:56.474409: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from IPython import display\n",
    "# import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random as python_random\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "from lazypredict.Supervised import LazyClassifier\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "yamnet_model = hub.load('https://tfhub.dev/google/yamnet/1') # if there's an \"SavedModel file does not exist at:\", delete that folder and rerun it\n",
    "vggish_model = hub.load('https://tfhub.dev/google/vggish/1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de65538e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>source</th>\n",
       "      <th>category</th>\n",
       "      <th>weight</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../data/interim/GoogleAudioSet_unbalanced_list...</td>\n",
       "      <td>Google_city</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../data/interim/GoogleAudioSet_unbalanced_list...</td>\n",
       "      <td>Google_city</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../data/interim/GoogleAudioSet_unbalanced_list...</td>\n",
       "      <td>Google_nature</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../data/interim/GoogleAudioSet_unbalanced_list...</td>\n",
       "      <td>Google_city</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../data/interim/GoogleAudioSet_unbalanced_list...</td>\n",
       "      <td>Google_city</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13662</th>\n",
       "      <td>../data/interim/GoogleAudioSet_unbalanced_list...</td>\n",
       "      <td>Google_city</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13663</th>\n",
       "      <td>../data/interim/GoogleAudioSet_unbalanced_list...</td>\n",
       "      <td>Google_city</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13664</th>\n",
       "      <td>../data/interim/GoogleAudioSet_unbalanced_list...</td>\n",
       "      <td>Google_city</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13665</th>\n",
       "      <td>../data/interim/GoogleAudioSet_unbalanced_list...</td>\n",
       "      <td>Google_city</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13666</th>\n",
       "      <td>../data/interim/GoogleAudioSet_unbalanced_list...</td>\n",
       "      <td>Google_city</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13667 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    file         source  \\\n",
       "0      ../data/interim/GoogleAudioSet_unbalanced_list...    Google_city   \n",
       "1      ../data/interim/GoogleAudioSet_unbalanced_list...    Google_city   \n",
       "2      ../data/interim/GoogleAudioSet_unbalanced_list...  Google_nature   \n",
       "3      ../data/interim/GoogleAudioSet_unbalanced_list...    Google_city   \n",
       "4      ../data/interim/GoogleAudioSet_unbalanced_list...    Google_city   \n",
       "...                                                  ...            ...   \n",
       "13662  ../data/interim/GoogleAudioSet_unbalanced_list...    Google_city   \n",
       "13663  ../data/interim/GoogleAudioSet_unbalanced_list...    Google_city   \n",
       "13664  ../data/interim/GoogleAudioSet_unbalanced_list...    Google_city   \n",
       "13665  ../data/interim/GoogleAudioSet_unbalanced_list...    Google_city   \n",
       "13666  ../data/interim/GoogleAudioSet_unbalanced_list...    Google_city   \n",
       "\n",
       "       category  weight  fold  \n",
       "0             1       1     0  \n",
       "1             1       1     8  \n",
       "2             0       1     5  \n",
       "3             1       1     1  \n",
       "4             1       1     1  \n",
       "...         ...     ...   ...  \n",
       "13662         1       1     5  \n",
       "13663         1       1     3  \n",
       "13664         1       1     8  \n",
       "13665         1       1     8  \n",
       "13666         1       1     0  \n",
       "\n",
       "[13667 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all = pd.read_csv('../train_val_test_split/train_val_test_GoogleAudioSet.csv', index_col=0)\n",
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20a5f3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocessing(filename):\n",
    "    import pickle\n",
    "    \n",
    "    file = open(filename, 'rb')\n",
    "    output = pickle.load(file)\n",
    "#     output = pd.read_pickle(file)\n",
    "    wav_raw = output['y_aug']\n",
    "    wav_bg = output['y_bg_aug']\n",
    "    wav_fg = output['y_fg_aug']\n",
    "    \n",
    "    df_indices_raw = output['df_indices_aug']\n",
    "    df_indices_fg = output['df_indices_fg_aug']\n",
    "    df_indices_bg = output['df_indices_bg_aug']\n",
    "    \n",
    "    wt = output['wt']\n",
    "    mps_raw = output['mps_aug']\n",
    "    mps_fg = output['mps_fg_aug']\n",
    "    mps_bg = output['mps_bg_aug']\n",
    "    mps_raw = mps_raw[:,wt<=100].reshape(-1) # exclude the temporal modulation frequency >100 Hz\n",
    "    mps_fg = mps_fg[:,wt<=100].reshape(-1)\n",
    "    mps_bg = mps_bg[:,wt<=100].reshape(-1)\n",
    "    \n",
    "    file.close()\n",
    "\n",
    "    # Extract YAMNet embeddings for each frame\n",
    "    scores, embedding_tensor_raw, spectrogram = yamnet_model(wav_raw)\n",
    "    embedding_tensor_raw = tf.reduce_mean(embedding_tensor_raw, axis=0).numpy()\n",
    "\n",
    "    scores, embedding_tensor_bg, spectrogram = yamnet_model(wav_bg)\n",
    "    embedding_tensor_bg = tf.reduce_mean(embedding_tensor_bg, axis=0).numpy()\n",
    "\n",
    "    scores, embedding_tensor_fg, spectrogram = yamnet_model(wav_fg)\n",
    "    embedding_tensor_fg = tf.reduce_mean(embedding_tensor_fg, axis=0).numpy()\n",
    "    \n",
    "    \n",
    "    # Extract VGGish embeddings for each frame\n",
    "    vggish_embedding_raw = tf.reduce_mean(vggish_model(wav_raw), axis=0).numpy()\n",
    "    vggish_embedding_bg = tf.reduce_mean(vggish_model(wav_bg), axis=0).numpy()\n",
    "    vggish_embedding_fg = tf.reduce_mean(vggish_model(wav_fg), axis=0).numpy()\n",
    "   \n",
    "    return embedding_tensor_raw, embedding_tensor_bg, embedding_tensor_fg, mps_raw, mps_bg, mps_fg, df_indices_raw, df_indices_bg, df_indices_fg, vggish_embedding_raw, vggish_embedding_bg, vggish_embedding_fg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16e31444",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint path: /Users/andrewchang/panns_data/Cnn14_mAP=0.431.pth\n",
      "Using CPU.\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "5300\n",
      "5400\n",
      "5500\n",
      "5600\n",
      "5700\n",
      "5800\n",
      "5900\n",
      "6000\n",
      "6100\n",
      "6200\n",
      "6300\n",
      "6400\n",
      "6500\n",
      "6600\n",
      "6700\n",
      "6800\n",
      "6900\n",
      "7000\n",
      "7100\n",
      "7200\n",
      "7300\n",
      "7400\n",
      "7500\n",
      "7600\n",
      "7700\n",
      "7800\n",
      "7900\n",
      "8000\n",
      "8100\n",
      "8200\n",
      "8300\n",
      "8400\n",
      "8500\n",
      "8600\n",
      "8700\n",
      "8800\n",
      "8900\n",
      "9000\n",
      "9100\n",
      "9200\n",
      "9300\n",
      "9400\n",
      "9500\n",
      "9600\n",
      "9700\n",
      "9800\n",
      "9900\n",
      "10000\n",
      "10100\n",
      "10200\n",
      "10300\n",
      "10400\n",
      "10500\n",
      "10600\n",
      "10700\n",
      "10800\n",
      "10900\n",
      "11000\n",
      "11100\n",
      "11200\n",
      "11300\n",
      "11400\n",
      "11500\n",
      "11600\n",
      "11700\n",
      "11800\n",
      "11900\n",
      "12000\n",
      "12100\n",
      "12200\n",
      "12300\n",
      "12400\n",
      "12500\n",
      "12600\n",
      "12700\n",
      "12800\n",
      "12900\n",
      "13000\n",
      "13100\n",
      "13200\n",
      "13300\n",
      "13400\n",
      "13500\n",
      "13600\n",
      "13436.996054172516\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import panns_inference\n",
    "from panns_inference import AudioTagging, SoundEventDetection, labels\n",
    "import pickle\n",
    "from librosa import resample\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "wav_raw_list = []\n",
    "wav_bg_list = []\n",
    "wav_fg_list = []\n",
    "for index, row in df_all.iterrows():\n",
    "    filename = '../data/interim/augmented_'+row['file'][16:-6]+'.pkl'\n",
    "    file = open(filename, 'rb')\n",
    "    output = pickle.load(file)\n",
    "    wav_raw_list.append(np.pad(output['y_aug'], (0,160000-len(output['y_aug'])),'mean'))\n",
    "    wav_bg_list.append(np.pad(output['y_bg_aug'], (0,160000-len(output['y_bg_aug'])),'mean'))\n",
    "    wav_fg_list.append(np.pad(output['y_fg_aug'], (0,160000-len(output['y_fg_aug'])),'mean'))\n",
    "    file.close()\n",
    "    \n",
    "wav_raw = resample(np.stack(wav_raw_list), orig_sr=16000, target_sr=32000, axis=1)\n",
    "del wav_raw_list\n",
    "wav_bg = resample(np.stack(wav_bg_list), orig_sr=16000, target_sr=32000, axis=1)\n",
    "del wav_bg_list\n",
    "wav_fg = resample(np.stack(wav_fg_list), orig_sr=16000, target_sr=32000, axis=1)\n",
    "del wav_fg_list\n",
    "    \n",
    "\n",
    "n_file = 0\n",
    "clipwise_output_raw_list = []\n",
    "clipwise_output_bg_list = []\n",
    "clipwise_output_fg_list = []\n",
    "embedding_raw_list = []\n",
    "embedding_bg_list = []\n",
    "embedding_fg_list = []\n",
    "file_step = 100\n",
    "\n",
    "at = AudioTagging(checkpoint_path=None, device='cuda')\n",
    "while n_file < len(df_all):\n",
    "    print(str(n_file))\n",
    "    (clipwise_output_raw, embedding_raw) = at.inference(wav_raw[n_file:min(n_file+file_step,len(df_all))])\n",
    "    (clipwise_output_bg, embedding_bg) = at.inference(wav_bg[n_file:min(n_file+file_step,len(df_all))])\n",
    "    (clipwise_output_fg, embedding_fg) = at.inference(wav_fg[n_file:min(n_file+file_step,len(df_all))])\n",
    "    n_file += file_step\n",
    "    \n",
    "    clipwise_output_raw_list.append(clipwise_output_raw)\n",
    "    clipwise_output_bg_list.append(clipwise_output_bg)\n",
    "    clipwise_output_fg_list.append(clipwise_output_fg)\n",
    "    embedding_raw_list.append(embedding_raw)\n",
    "    embedding_bg_list.append(embedding_bg)\n",
    "    embedding_fg_list.append(embedding_fg)\n",
    "\n",
    "    \n",
    "panns_clip_raw = np.concatenate(clipwise_output_raw_list, axis=0)\n",
    "del clipwise_output_raw_list\n",
    "\n",
    "panns_clip_bg = np.concatenate(clipwise_output_bg_list, axis=0)\n",
    "del clipwise_output_bg_list\n",
    "\n",
    "panns_clip_fg = np.concatenate(clipwise_output_fg_list, axis=0)\n",
    "del clipwise_output_fg_list\n",
    "\n",
    "panns_embedding_raw = np.concatenate(embedding_raw_list, axis=0)\n",
    "del embedding_raw_list\n",
    "\n",
    "panns_embedding_bg = np.concatenate(embedding_bg_list, axis=0)\n",
    "del embedding_bg_list\n",
    "\n",
    "panns_embedding_fg = np.concatenate(embedding_fg_list, axis=0)\n",
    "del embedding_fg_list\n",
    "\n",
    "\n",
    "\n",
    "print(time.time()-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25e3376a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../data/processed/20230310_dataAugmentation/panns_clip_raw.npy', panns_clip_raw)\n",
    "np.save('../data/processed/20230310_dataAugmentation/panns_clip_bg.npy', panns_clip_bg)\n",
    "np.save('../data/processed/20230310_dataAugmentation/panns_clip_fg.npy', panns_clip_fg)\n",
    "np.save('../data/processed/20230310_dataAugmentation/panns_embedding_raw.npy', panns_embedding_raw)\n",
    "np.save('../data/processed/20230310_dataAugmentation/panns_embedding_bg.npy', panns_embedding_bg)\n",
    "np.save('../data/processed/20230310_dataAugmentation/panns_embedding_fg.npy', panns_embedding_fg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b907e47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seconds: 5145.981775045395\n"
     ]
    }
   ],
   "source": [
    "embedding_raw_list = []\n",
    "embedding_bg_list = []\n",
    "embedding_fg_list = []\n",
    "mps_raw_list = []\n",
    "mps_bg_list = []\n",
    "mps_fg_list = []\n",
    "indices_raw_list = []\n",
    "indices_bg_list = []\n",
    "indices_fg_list = []\n",
    "vgg_raw_list = []\n",
    "vgg_bg_list = []\n",
    "vgg_fg_list = []\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "for index, row in df_all.iterrows():\n",
    "    filename = '../data/interim/augmented_'+row['file'][16:-6]+'.pkl'\n",
    "    embedding_tensor_raw, embedding_tensor_bg, embedding_tensor_fg, mps_raw, mps_bg, mps_fg, df_indices_raw, df_indices_bg, df_indices_fg, vggish_embedding_raw, vggish_embedding_bg, vggish_embedding_fg = data_preprocessing(filename)\n",
    "    \n",
    "    embedding_raw_list.append(embedding_tensor_raw)\n",
    "    embedding_bg_list.append(embedding_tensor_bg)\n",
    "    embedding_fg_list.append(embedding_tensor_fg)\n",
    "    mps_raw_list.append(mps_raw)\n",
    "    mps_bg_list.append(mps_bg)\n",
    "    mps_fg_list.append(mps_fg)\n",
    "    indices_raw_list.append(df_indices_raw)\n",
    "    indices_bg_list.append(df_indices_bg)\n",
    "    indices_fg_list.append(df_indices_fg)\n",
    "    vgg_raw_list.append(vggish_embedding_raw)\n",
    "    vgg_bg_list.append(vggish_embedding_bg)\n",
    "    vgg_fg_list.append(vggish_embedding_fg)\n",
    "\n",
    "    \n",
    "print('seconds: '+str(time.time()-start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1bda728",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_raw_matrix = np.stack(embedding_raw_list, axis=0)\n",
    "embedding_bg_matrix = np.stack(embedding_bg_list, axis=0)\n",
    "embedding_fg_matrix = np.stack(embedding_fg_list, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08770546",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_indices_raw = pd.concat(indices_raw_list, ignore_index=True)\n",
    "df_indices_bg = pd.concat(indices_bg_list, ignore_index=True)\n",
    "df_indices_fg = pd.concat(indices_fg_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18e2aecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "mps_raw_matrix = np.stack(mps_raw_list)\n",
    "mps_bg_matrix = np.stack(mps_bg_list)\n",
    "mps_fg_matrix = np.stack(mps_fg_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb88ce4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_raw_matrix = np.stack(vgg_raw_list, axis=0)\n",
    "vgg_bg_matrix = np.stack(vgg_bg_list, axis=0)\n",
    "vgg_fg_matrix = np.stack(vgg_fg_list, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c9b29161",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../data/processed/20230310_dataAugmentation/embedding_raw_matrix.npy', embedding_raw_matrix)\n",
    "np.save('../data/processed/20230310_dataAugmentation/embedding_bg_matrix.npy', embedding_bg_matrix)\n",
    "np.save('../data/processed/20230310_dataAugmentation/embedding_fg_matrix.npy', embedding_fg_matrix)\n",
    "\n",
    "np.save('../data/processed/20230310_dataAugmentation/vgg_raw_matrix.npy', vgg_raw_matrix)\n",
    "np.save('../data/processed/20230310_dataAugmentation/vgg_bg_matrix.npy', vgg_bg_matrix)\n",
    "np.save('../data/processed/20230310_dataAugmentation/vgg_fg_matrix.npy', vgg_fg_matrix)\n",
    "\n",
    "np.save('../data/processed/20230310_dataAugmentation/mps_raw_matrix.npy', mps_raw_matrix)\n",
    "np.save('../data/processed/20230310_dataAugmentation/mps_bg_matrix.npy', mps_bg_matrix)\n",
    "np.save('../data/processed/20230310_dataAugmentation/mps_fg_matrix.npy', mps_fg_matrix)\n",
    "\n",
    "df_indices_raw.to_csv('../data/processed/20230310_dataAugmentation/df_indices_raw.csv')\n",
    "df_indices_bg.to_csv('../data/processed/20230310_dataAugmentation/df_indices_bg.csv')\n",
    "df_indices_fg.to_csv('../data/processed/20230310_dataAugmentation/df_indices_fg.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e561ca42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
